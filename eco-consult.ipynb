{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caed516",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade typing-extensions pydantic-core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880145b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12932b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aae13bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No secrets files found. Valid paths for a secrets.toml file are: C:\\Users\\HP\\.streamlit\\secrets.toml, C:\\Users\\HP\\Desktop\\ALL\\.streamlit\\secrets.toml",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4760\\2571019073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# تعيين مفتاح API الخاص بـ OpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msecrets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value = self._parse(True)[key]\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapi_calling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\streamlit\\runtime\\secrets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\streamlit\\runtime\\secrets.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(self, print_exceptions)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mprint_exceptions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file_paths\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No secrets files found. Valid paths for a secrets.toml file are: C:\\Users\\HP\\.streamlit\\secrets.toml, C:\\Users\\HP\\Desktop\\ALL\\.streamlit\\secrets.toml"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "from streamlit_chat import message\n",
    "\n",
    "# تعيين مفتاح API الخاص بـ OpenAI\n",
    "openai.api_key = st.secrets[\"OPENAI_KEY\"]\n",
    "\n",
    "def api_calling(prompt, score):\n",
    "    context = \"You are an expert in environment and carbon footprint. \"\n",
    "    if score < 80:\n",
    "        context += \"The user needs advice on reducing carbon footprint. \"\n",
    "    prompt = context + prompt\n",
    "    completions = openai.Completion.create(\n",
    "        engine=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return completions.choices[0].text.strip()\n",
    "\n",
    "def calculate_score(selections):\n",
    "    points = {\"Wind energy\": 20, \"Solar energy\": 15, \"Electricity from the grid\": 10, \"Natural gas\": 5,\n",
    "              \"Walking\": 20, \"Bicycle/Electric bike\": 15, \"Public transport\": 10, \"Car\": 5,\n",
    "              \"Vegetarian\": 20, \"Mixed with moderate meat consumption\": 15, \"Mixed with high meat consumption\": 10, \"Meat only\": 5,\n",
    "              \"From 1 to 5\": 20, \"From 5 to 10\": 15, \"From 10 to 15\": 10, \"More than 15\": 5}\n",
    "    return sum(points[sel] for sel in selections)\n",
    "st.title(\"EcoShift\")\n",
    "st.title(\"Let's work together to identify and reduce your daily carbon footprint\")\n",
    "\n",
    "# استبيان\n",
    "st.header(\"Environmental Impact Survey\")\n",
    "questions = [\n",
    "    \"What is your primary source of energy today?\",\n",
    "    \"What is your main mode of transportation today?\",\n",
    "    \"What is your dietary system?\",\n",
    "    \"How much do you consume packaged and processed products today?\"\n",
    "]\n",
    "options = [\n",
    "    [\"Wind energy\", \"Solar energy\", \"Electricity from the grid\", \"Natural gas\"],\n",
    "    [\"Walking\", \"Bicycle/Electric bike\", \"Public transport\", \"Car\"],\n",
    "    [\"Vegetarian\", \"Mixed with moderate meat consumption\", \"Mixed with high meat consumption\", \"Meat only\"],\n",
    "    [\"From 1 to 5\", \"From 5 to 10\", \"From 10 to 15\", \"More than 15\"]\n",
    "]\n",
    "\n",
    "# تخزين اختيارات الاستبيان\n",
    "if 'selections' not in st.session_state:\n",
    "    st.session_state.selections = [None] * len(questions)\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    st.session_state.selections[i] = st.radio(question, options[i], key=f'q{i}')\n",
    "\n",
    "# تقديم الاستبيان وعرض النتيجة\n",
    "if st.button(\"Submit Survey\"):\n",
    "    score = calculate_score(st.session_state.selections)\n",
    "    st.session_state.score = score\n",
    "    st.write(f\"Your total score is: {score}\")\n",
    "else:\n",
    "    score = st.session_state.get('score', None)\n",
    "\n",
    "# شاتبوت\n",
    "st.header(\"Chat With Eco\")\n",
    "user_input = st.text_input(\"Write here\", key=\"input_chat\")\n",
    "\n",
    "if user_input and score is not None:\n",
    "    output = api_calling(user_input, score)\n",
    "    message(user_input, key=\"user_input\", avatar_style=\"icons\")\n",
    "    message(output, avatar_style=\"miniavs\", is_user=True, key=\"bot_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bf05fdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No secrets files found. Valid paths for a secrets.toml file are: C:\\Users\\HP\\.streamlit\\secrets.toml, C:\\Users\\HP\\Desktop\\ALL\\.streamlit\\secrets.toml",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4760\\1587020768.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Set OpenAI API key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msecrets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"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\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapi_calling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\streamlit\\runtime\\secrets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\streamlit\\runtime\\secrets.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(self, print_exceptions)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mprint_exceptions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file_paths\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No secrets files found. Valid paths for a secrets.toml file are: C:\\Users\\HP\\.streamlit\\secrets.toml, C:\\Users\\HP\\Desktop\\ALL\\.streamlit\\secrets.toml"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "from streamlit_chat import message\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = st.secrets[\"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\"]\n",
    "\n",
    "def api_calling(prompt, score):\n",
    "    context = \"You are an expert in environment and carbon footprint. \"\n",
    "    if score < 80:\n",
    "        context += \"The user needs advice on reducing carbon footprint. \"\n",
    "    prompt = context + prompt\n",
    "    completions = openai.Completion.create(\n",
    "        engine=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return completions.choices[0].text.strip()\n",
    "\n",
    "def calculate_score(selections):\n",
    "    points = {\n",
    "        \"Wind energy\": 20, \"Solar energy\": 15, \"Electricity from the grid\": 10, \"Natural gas\": 5,\n",
    "        \"Walking\": 20, \"Bicycle/Electric bike\": 15, \"Public transport\": 10, \"Car\": 5,\n",
    "        \"Vegetarian\": 20, \"Mixed with moderate meat consumption\": 15, \"Mixed with high meat consumption\": 10, \"Meat only\": 5,\n",
    "        \"From 1 to 5\": 20, \"From 5 to 10\": 15, \"From 10 to 15\": 10, \"More than 15\": 5\n",
    "    }\n",
    "    return sum(points[sel] for sel in selections)\n",
    "\n",
    "st.title(\"EcoShift\")\n",
    "st.header(\"Let's work together to identify and reduce your daily carbon footprint\")\n",
    "\n",
    "# Environmental Impact Survey\n",
    "st.header(\"Environmental Impact Survey\")\n",
    "questions = [\n",
    "    \"What is your primary source of energy today?\",\n",
    "    \"What is your main mode of transportation today?\",\n",
    "    \"What is your dietary system?\",\n",
    "    \"How much do you consume packaged and processed products today?\"\n",
    "]\n",
    "options = [\n",
    "    [\"Wind energy\", \"Solar energy\", \"Electricity from the grid\", \"Natural gas\"],\n",
    "    [\"Walking\", \"Bicycle/Electric bike\", \"Public transport\", \"Car\"],\n",
    "    [\"Vegetarian\", \"Mixed with moderate meat consumption\", \"Mixed with high meat consumption\", \"Meat only\"],\n",
    "    [\"From 1 to 5\", \"From 5 to 10\", \"From 10 to 15\", \"More than 15\"]\n",
    "]\n",
    "\n",
    "# Store survey selections\n",
    "if 'selections' not in st.session_state:\n",
    "    st.session_state.selections = [None] * len(questions)\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    st.session_state.selections[i] = st.radio(question, options[i], key=f'q{i}')\n",
    "\n",
    "# Submit survey and display results\n",
    "if st.button(\"Submit Survey\"):\n",
    "    score = calculate_score(st.session_state.selections)\n",
    "    st.session_state.score = score\n",
    "    st.write(f\"Your total score is: {score}\")\n",
    "else:\n",
    "    score = st.session_state.get('score', None)\n",
    "\n",
    "# Chatbot\n",
    "st.header(\"Chat With Eco\")\n",
    "user_input = st.text_input(\"Write here\", key=\"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\")\n",
    "\n",
    "if user_input and score is not None:\n",
    "    output = api_calling(user_input, score)\n",
    "    message(user_input, key=\"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\", avatar_style=\"icons\")\n",
    "    message(output, avatar_style=\"miniavs\", is_user=True, key=\"bot_response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "badda997",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4760\\1040273290.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"text-davinci-003\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\openai\\lib\\_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"help me\"\n",
    "\n",
    "# Request a completion\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "# Print the completion\n",
    "print(response.choices[0].text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "144518ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4760\\2052361277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"text-davinci-003\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\openai\\lib\\_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"Once upon a time\"\n",
    "\n",
    "# Request a completion\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "# Print the completion\n",
    "print(response[\"choices\"][0][\"text\"].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4cdbe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp37-cp37m-win_amd64.whl (153 kB)\n",
      "     ------------------------------------ 153.2/153.2 kB 175.9 kB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     ------------------------------------ 268.8/268.8 kB 828.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from transformers) (4.11.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp37-cp37m-win_amd64.whl (270 kB)\n",
      "     -------------------------------------- 270.2/270.2 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from transformers) (22.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.2-cp37-none-win_amd64.whl (268 kB)\n",
      "     -------------------------------------- 269.0/269.0 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "     ------------------------------------ 143.0/143.0 kB 386.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Installing collected packages: tokenizers, safetensors, regex, pyyaml, fsspec, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.2 fsspec-2023.1.0 huggingface-hub-0.16.4 pyyaml-6.0.1 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.13.3 transformers-4.30.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "959bf081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp37-cp37m-win_amd64.whl (162.6 MB)\n",
      "     -------------------------------------- 162.6/162.6 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp37-cp37m-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.13.1-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.13.1 torchaudio-0.13.1 torchvision-0.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3513e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|████████████████████████████████████████████████████████| 483/483 [00:00<00:00, 96.9kB/s]\n",
      "C:\\Users\\HP\\anaconda3\\envs\\newenv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading model.safetensors:  86%|█████████████████████████████████████████▎      | 231M/268M [03:42<00:12, 3.07MB/s]"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertModel, DistilBertTokenizer\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = TFDistilBertModel.from_pretrained(model_name)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize your text\n",
    "text = \"Hello, how are you?\"\n",
    "tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "# Pass tokens through the model\n",
    "outputs = model(tokens)\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Use the embeddings\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340365e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
